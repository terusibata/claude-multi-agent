# 06 - 本番運用

## スケーリング設計

### キャパシティプランニング

| パラメータ | 値 | 根拠 |
|-----------|-----|------|
| コンテナあたりリソース | 2 CPU / 2GB RAM | Anthropic 推奨値 + データ分析考慮 |
| ホストあたりコンテナ数 | 16〜32 | メモリ 2GB/コンテナ × ホストスペック |
| 推奨ホストスペック | 16 CPU / 64GB RAM | コンテナ×32 + オーバーヘッド |
| Warm Pool サイズ | 同時接続数の 10〜20% | コールドスタート回避 |

### スケーリング戦略

```
               ┌─ Auto Scaling Group ─────────────────┐
               │                                       │
  Scale Out    │  ┌──────┐ ┌──────┐ ┌──────┐          │  Scale In
  ──────────►  │  │Host 1│ │Host 2│ │Host 3│ ...      │  ◄──────────
  同時コンテナ  │  └──────┘ └──────┘ └──────┘          │  コンテナ利用率
  > 閾値       │                                       │  < 閾値
               └───────────────────────────────────────┘
```

| メトリクス | スケールアウト | スケールイン |
|-----------|--------------|------------|
| コンテナ利用率 | > 70% | < 30% |
| Warm Pool 枯渇 | プール空が3回連続 | - |
| ホスト CPU | > 80% | < 40% |
| ホストメモリ | > 75% | < 40% |

### コスト最適化

| 戦略 | 削減効果 | 実装難度 |
|------|---------|---------|
| Spot インスタンス (非本番ホスト) | 最大 60〜90% | 中 |
| 夜間・週末のスケールダウン | 30〜50% | 低 |
| コンテナリソースの適正化 (VPA 相当) | 20〜30% | 低 |
| ベースイメージの最適化（サイズ削減） | 間接的（起動時間短縮） | 低 |

## 障害復旧

### 障害パターンと対応

| 障害 | 検知方法 | 自動復旧 | 手動対応 |
|------|---------|---------|---------|
| コンテナクラッシュ | ヘルスチェック失敗 | 新コンテナ割り当て + S3 から復元 | 不要 |
| ホスト障害 | EC2 ステータスチェック | ASG が新ホスト起動 | 不要 |
| Docker デーモン停止 | systemd watchdog | systemd 自動再起動 | 再起動失敗時に確認 |
| S3 障害 | S3 エラーレスポンス | リトライ (exponential backoff) | AWS に問い合わせ |
| Redis 障害 | 接続エラー | Redis Sentinel/Cluster フェイルオーバー | 不要 |
| Proxy クラッシュ | Unix Socket 接続エラー | Proxy プロセス自動再起動 | 不要 |

### データ損失の最小化

```
コンテナクラッシュ時のデータ復旧フロー:

1. ヘルスチェック失敗を検知（Unix Socket 経由で /health 応答なし）
2. 実行中リクエストに "container_lost" エラーを返却
3. Redis から会話のコンテナメタデータを取得
4. 新コンテナを割り当て（Warm Pool → 新規作成）
5. 新しい Unix Socket ペア + Proxy を起動
6. S3 から最新のワークスペースファイルを同期
7. ユーザーに「セッションが復旧された」旨を通知
   ※ 最後の同期以降の未保存変更は失われる可能性あり
```

### 定期同期による保護

- エージェント実行中、**ツール結果ごとに差分ファイルを S3 に同期**する
- これにより、コンテナクラッシュ時のデータ損失を最小限に抑える
- 同期は非同期で実行し、エージェントの実行を妨げない

## 監視設計

### メトリクス

#### インフラメトリクス

| メトリクス | 収集方法 | アラート閾値 |
|-----------|---------|------------|
| ホスト CPU 使用率 | cAdvisor / CloudWatch | > 85% |
| ホストメモリ使用率 | cAdvisor / CloudWatch | > 80% |
| ディスク使用率 | node_exporter | > 80% |
| コンテナ数 (アクティブ) | Docker API | > ホスト上限の 90% |
| Warm Pool サイズ | カスタムメトリクス | < 最小サイズ |

#### アプリケーションメトリクス

| メトリクス | 説明 | アラート閾値 |
|-----------|------|------------|
| コンテナ起動時間 | 割り当て〜Ready までの時間 | P95 > 10秒 |
| リクエスト成功率 | 200 / total | < 95% |
| コンテナクラッシュ率 | crash / total containers | > 5% |
| S3 同期エラー率 | error / total syncs | > 1% |
| TTL による破棄数 | 時間あたりの GC 数 | 急増時アラート |
| Proxy レイテンシ | Unix Socket 経由の往復時間 | P95 > 100ms |
| Proxy ブロック率 | blocked / total proxy requests | 急増時アラート |

### ログ戦略

```json
{
  "timestamp": "2026-02-07T10:30:00Z",
  "level": "INFO",
  "service": "workspace-orchestrator",
  "event": "container_created",
  "conversation_id": "conv-123",
  "tenant_id": "tenant-456",
  "container_id": "ws-abc",
  "source": "warm_pool",
  "network_mode": "none",
  "duration_ms": 1200
}
```

```json
{
  "timestamp": "2026-02-07T10:30:05Z",
  "level": "INFO",
  "service": "credential-proxy",
  "event": "request_forwarded",
  "container_id": "ws-abc",
  "method": "POST",
  "destination": "bedrock-runtime.us-east-1.amazonaws.com",
  "status": 200,
  "duration_ms": 450
}
```

### ダッシュボード構成

```
┌─ Workspace Isolation Dashboard ─────────────────────┐
│                                                       │
│  ┌─ コンテナ概要 ──┐  ┌─ リソース使用率 ──────────┐  │
│  │ Active:   24    │  │ [CPU グラフ]              │  │
│  │ Idle:     8     │  │ [メモリグラフ]             │  │
│  │ Pool:     3     │  │ [ディスクグラフ]            │  │
│  │ Total:    35    │  │                           │  │
│  └────────────────┘  └───────────────────────────┘  │
│                                                       │
│  ┌─ コンテナ起動時間 ─┐  ┌─ エラー率 ──────────────┐ │
│  │ [ヒストグラム]     │  │ [時系列グラフ]          │  │
│  │ P50: 1.2s         │  │ Container crash: 0.1%   │  │
│  │ P95: 4.5s         │  │ S3 sync error: 0.05%    │  │
│  │ P99: 8.2s         │  │ Health check fail: 0.2% │  │
│  └───────────────────┘  └─────────────────────────┘  │
│                                                       │
│  ┌─ Proxy メトリクス ─────────────────────────────┐  │
│  │ Requests/min: 1,240   Blocked: 3 (0.2%)       │  │
│  │ Avg latency: 12ms    P95 latency: 45ms        │  │
│  │ Top domains: bedrock-runtime (85%), pypi (12%) │  │
│  └───────────────────────────────────────────────┘  │
└───────────────────────────────────────────────────────┘
```

## 実装ロードマップ

### Phase 1: コンテナ隔離 + セキュリティ基盤（公式推奨準拠）

**目標**: Anthropic 公式セキュアデプロイメントガイドに準拠した基本構成を構築

- [ ] Workspace ベースイメージの作成（プリインストール済みライブラリ含む）
- [ ] ContainerOrchestrator の実装（Docker API 連携）
- [ ] `--network none` + Unix Socket 通信の実装
- [ ] Credential Injection Proxy の実装（AWS SigV4 署名注入）
- [ ] ドメインホワイトリスト適用
- [ ] S3 ファイル同期の実装
- [ ] TTL ベースの GC 実装
- [ ] リソース制限の適用（CPU 2core / Memory 2GB / PIDs 100 / Disk 5GB）
- [ ] seccomp（Docker デフォルトプロファイル）有効化
- [ ] read-only rootfs + noexec tmpfs 適用
- [ ] `no-new-privileges` + Capability drop
- [ ] IPC 隔離 (`--ipc private`)
- [ ] 基本的なヘルスチェック（Unix Socket 経由）
- [ ] Proxy 監査ログの実装

### Phase 2: 運用品質 + Warm Pool

**目標**: コールドスタート最適化と運用監視の強化

- [ ] Warm Pool の実装（Redis ベース、マルチインスタンス対応）
- [ ] userns-remap の有効化
- [ ] カスタム seccomp プロファイルの適用
- [ ] 監視ダッシュボードの構築
- [ ] アラート設定
- [ ] Proxy レイテンシ最適化
- [ ] コンテナ起動時間のプロファイリングと最適化

### Phase 3: セキュリティ強化

**目標**: カーネルレベルの隔離とセキュリティ監査

- [ ] gVisor (runsc) ランタイムの導入
- [ ] AppArmor プロファイルの適用
- [ ] セキュリティ監査ログの集約と分析
- [ ] ペネトレーションテスト（コンテナエスケープ試行）
- [ ] ドメインホワイトリストの厳格化

### Phase 4: スケーリング

**目標**: マルチホスト対応とコスト最適化

- [ ] マルチホスト対応（コンテナスケジューリング）
- [ ] Auto Scaling の実装
- [ ] Spot インスタンス対応
- [ ] Firecracker microVM への移行検討
- [ ] コスト分析とリソース最適化

### Phase 間の依存関係

```
Phase 1 ─────► Phase 2 ─────► Phase 3
  │                              │
  │              Phase 4 ◄───────┘
  │                │
  └────────────────┘ (Phase 1 完了後に Phase 4 並行可能)
```

> **Phase 1 のスコープについて**: 旧設計では seccomp、ネットワーク隔離、リソース制限の一部が
> Phase 2〜3 に先送りされていたが、Anthropic 公式ガイドではこれらを基本設定として記載している。
> Phase 1 で公式推奨の全セキュリティ設定を適用することで、初期デプロイから安全な状態を確保する。